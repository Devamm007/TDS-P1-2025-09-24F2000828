# Self-Hosted-LLM-DevOps-Engine ü§ñ

[![Python 3.11+](https://img.shields.io/badge/Python-3.11%2B-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/Framework-FastAPI-009688.svg)](https://fastapi.tiangolo.com/)
[![GitHub API](https://img.shields.io/badge/Automation-GitHub_API-black.svg)](https://docs.github.com/en/rest)

## üéØ Overview

The **Self-Hosted-LLM-DevOps-Engine** is a API-driven backend service designed to automate the process of turning a simple task brief into a working code repository. Users can send a JSON payload to the running API, which then orchestrates the entire development and deployment flow: LLM code generation (simulated here) $\rightarrow$ GitHub Repository creation $\rightarrow$ GitHub Pages deployment.

This engine is built for **self-hosting**, allowing users to secure their own API keys and secrets for full control over the process.

## üìë TDS-Project-1

Some code content is particularly for my project submission and evaluation, a seperate version will be avaible for users to use themselves and can use their own self hosted API-endpoint. [https://github.com/Devamm007/Self-Hosted-LLM-DevOps-Engine Coming Soon!]

My evaluators will:
Publish a Google Form where I will be submitting my API URL, secret, and this GitHub repo URL
For each submission, create a unique task request.
POST the request to student's latest API URL.
If the response is not HTTP 200, try up to 3 times over 3-24 hours. Then fail.
Accept POST requests on the evaluation_url. Add it to queue to evaluate and return a HTTP 200 response.
Evaluate the repo based on the task-specific as well as common checks and log these.
Repo-level rule-based checks (e.g. LICENSE is MIT)
LLM-based static checks (e.g. code quality, README.md quality)
Dynamic checks (e.g. use Playwright to load your page, run and test your app)
Save the results in a results table.
For all {"round": 1} requests, generate and POST a unique round 2 task request (even if checks failed).
Publish the database after the deadline.
My evaluators may, at their discretion, send up to 3 such tasks.

This is payload's structure to POST to evaluation.url:
```
{
  # Copy these from the request
  "email": "...",
  "task": "captcha-solver-...",
  "round": 1,
  "nonce": "ab12-...",
  # Send these based on your GitHub repo and commit
  "repo_url": "https://github.com/user/repo",
  "commit_sha": "abc123",
  "pages_url": "https://user.github.io/repo/",
}
```

## üõ†Ô∏è Prerequisites

Before you begin, ensure you have the following ready:

1.  **Python 3.11+** installed.
2.  **A GitHub Account** for repository creation.
3.  **An OpenAI API Key** (or another LLM service key) if you intend to replace the simulated LLM function.

---

## üîë Configuration & Setup

### 1. Generate Required Tokens

You need to set up three critical environment variables to run the application:

| Variable | Purpose | How to Get It |
| :--- | :--- | :--- |
| **`GITHUB_TOKEN`** | Used to create repositories and push code. | Generate a **Personal Access Token (PAT)**. Settings > Developer Settings > Personal Access Tokens > Fined-grained tokens, create token with Repository access: "All repositories" and Permissions: Administration, Contents, Pages, Workflows (read and write) and Metadata |
| **`LLM_API_KEY`** | Used for communication with the LLM for code generation. | Obtain this key from any platform of your choice. |
| **`SECRET`** | A private, custom string used to validate incoming requests to your API. So only those who have secret can use your API-endpoint if exposed. | Choose any long, random, and secure string (e.g., generated by a password manager). |

### 2. Configure the `.env` File

Create a file named **`.env`** in your main application directory and populate it with the keys you generated in the previous step:

```
# A unique secret key for API request validation
SECRET="your_long_random_and_secure_secret_key_here"

# Your Personal Access Token for GitHub API access with required settings
GITHUB_TOKEN="ghp_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"

# Your API key for LLM-Integration
OPENAI_API_KEY="sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
```

---

## üõ†Ô∏è Installation and Execution

You have a few options for installing the requirements and running the server.

### Option 1: Using UV (Recommended)

The `uv` tool is a modern, fast Python package installer and executor.

1.  **Install UV:**
    ```bash
    pip install uv
    ```

2.  **Run the Application:**
    Since `main.py` includes a `script` header with dependencies, `uv` can install them into a temporary virtual environment and execute the file in one step.

    ```bash
    uv run main.py
    ```

### Option 2: Using `requirements.txt`

1.  **Install Dependencies:**
    It is highly recommended to use a virtual environment or you can directly install dependencies.
    ```bash
    # Create and activate a virtual environment
    python3 -m venv venv
    source venv/bin/activate  # On Linux/macOS
    # venv\Scripts\activate   # On Windows

    # Install the dependencies
    pip install -r requirements.txt
    ```

3.  **Run the Application:**
    ```bash
    python main.py
    # OR
    python3 main.py
    ```
    *(Remember to keep the virtual environment active, or use `uv run main.py` to handle the environment automatically.)*